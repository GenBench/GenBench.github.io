---
permalink: /workshop_programme/
title: "Workshop programme"
toc: false
author_profile: false
layout: single_wide
toc_sticky: true
excerpt: "The programme of the first workshop on (benchmarking) generalisation in NLP"
header:
  overlay_color: "#268"
---

# Programme

Note that all time slots listed below are in Singapore Standard Time (GMT+8), and that all activities take place in the Central Ballroom 3.

## Morning programme

### <span style="color:grey">09:00-09:15 AM —</span> Opening remarks
### <span style="color:grey">09:15-10:00 AM —</span> Keynote 1, by Anna Rogers
![Anna Rogers Speaker](/img/speakers/anna.jpg){:width="150px"}

> <b>Title:</b> A sanity check on emergent properties
> 
> <b>Abstract:</b> One of the frequent points in the mainstream narrative about large language models is that they have "emergent properties" (sometimes even dangerous enough to be considered existential risk to mankind). However, there is much disagreement about even the very definition of such properties. If they are understood as a kind of generalization beyond training data - as something that a model does without being explicitly trained for it - I argue that we have not in fact established the existence of any such properties, and at the moment we do not even have the methodology for doing so.


### <span style="color:grey">10:00-11:15 AM —</span> Poster session 1

<!-- <details> -->
<!-- <summary>Click to toggle an overview of the posters that will be presented in this session.</summary> -->
<ul>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Temporal Generalizability in Multimodal Misinformation Detection</b> <br>
      Nataliya Stepanova and Björn Ross
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Robust Generalization Strategies for Morpheme Glossing in an Endangered Language Documentation Context</b> <br>
      Michael Ginn and Alexis Palmer
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Syntax-Guided Transformers: Elevating Compositional Generalization and Grounding in Multimodal Environments</b> <br>
      Danial Kamali and Parisa Kordjamshidi
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Inductive Bias Is in the Eye of the Beholder</b> <br>
      Michael Wilson and Robert Frank
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> On using distribution-based compositionality assessment to evaluate compositional generalisation in machine translation</b> <br>
      Anssi Moisio, Mathias Creutz, and Mikko Kurimo
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> The ICL consistency test</b> <br>
      Lucas Weber, Elia Bruni, and Dieuwke Hupkes
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Generalizability and Robustness of Large Language Models Detecting Alzheimer’s Disease from Speech</b> <br>
      Jekaterina Novikova
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models</b> <br>
      Jirui Qi, Raquel Fernández, and Arianna Bisazza
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks</b> <br>
      Kaiser Sun, Adina Williams, and Dieuwke Hupkes
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation</b> <br>
      Francois Meyer and Jan Buys
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> The language of prompting: What linguistic properties make a prompt successful?</b> <br>
      Alina Leidinger, Robert Van Rooij, and Ekaterina Shutova
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> IRFL: Image Recognition of Figurative Language</b> <br>
     Ron Yosef, Yonatan Bitton, and Dafna Shahaf
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning</b> <br>
      An-Zi Yen and Wei-Ling Hsu
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> mReFinED: An Efficient End-to-End Multilingual Entity Linking System</b> <br>
      Peerat Limkonchotiwat, Weiwei Cheng, Christos Christodoulopoulos, Amir Saffari, and Jens Lehmann
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Noisy Self-Training with Synthetic Queries for Dense Retrieval</b> <br>
      Fan Jiang, Tom Drummond, and Trevor Cohn
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains</b> <br>
      Chia-Chien Hung, Wiem Ben Rim, Lindsay Frost, Lars Bruckner, and Carolin Lawrence
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens</b> <br>
      David Stap, Vlad Niculae, and Christof Monz
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4</b> <br>
     Jeonghwan Kim, Giwon Hong, Sung-Hyon Myaeng, and Joyce Jiyoung Whang
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Quantifying the Dialect Gap in Large Language Models and its Causes Across Languages</b> <br>
      Anjali Kantharuban, Ivan Vulić, and Anna Korhonen
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench</b> <br>
      Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, and Robin Jia
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers</b> <br>
      Osman Batur İnce, Tanin Zeraati, Semih Yagcioglu, Yadollah Yaghoobzadeh, Erkut Erdem, and Aykut Erdem
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization</b> <br>
      Ningyu Xu, Qi Zhang, Jingting Ye, Menghan Zhang, and Xuanjing Huang
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Test-Time Self-Adaptive Small Language Models for Question Answering</b> <br>
     Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, and Jong C. Park
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Estimating Large Language Model Capabilities without Labeled Test Data</b> <br>
     Harvey Yiyun Fu, Qinyuan Ye, Albert Xu, Xiang Ren, and Robin Jia
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> The Less the Merrier? Investigating Language Representation in Multilingual Models</b> <br>
     Hellina Hailu Nigatu, Atnafu Lambebo Tonja, and Jugal Kalita
  </li>
  <li>
      <b><span style="color:grey">10:00-11:15 AM — </span> Test-time Augmentation for Factual Probing</b> <br>
     Go Kamoda, Benjamin Heinzerling, Keisuke Sakaguchi, and Kentaro Inui
  </li>
  
  
</ul>
<!-- </details> -->


### <span style="color:grey">10:30-11:00 AM —</span> Coffee break
### <span style="color:grey">11:15-12:00 PM —</span> Keynote 2, by Adina Williams
![Adina Williams Speaker](/img/speakers/adina.jpg){:width="150px"}
<b>Title:</b> Evaluation after the LLM boom: frustrations, fallacies, and the future

### <span style="color:grey">12:00-12:30 PM —</span> CBT spotlights
- <b><span style="color:grey">12:00-12:08 PM — </span> GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding </b> <br>
Andor Diera, Abdelhalim Dahou, Lukas Galke, Fabian Karl, Ansgar Scherp

- <b><span style="color:grey">12:08-12:15 PM — </span> Latent Feature-based Data Splits to Improve Generalisation Evaluation: A Hate Speech Detection Case Study</b> <br>
Maike Züfle, Verna Dankers, Ivan Titov

- <b><span style="color:grey">12:15-12:23 PM — </span> On using distribution-based compositionality assessment to evaluate compositional generalisation in machine translation</b> <br>
Anssi Moisio, Mathias Creutz, Mikko Kurimo

- <b><span style="color:grey">12:23-12:30 PM — </span> Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models</b> <br>
Jirui Qi, Raquel Fernández, Arianna Bisazza

## <span style="color:grey"> 12:30-14:00 PM —</span> Lunch break

## Afternoon programme
### <span style="color:grey">14:00-14:45 PM —</span> Keynote 3, by Tatsunori Hashimoto
![Tatsunori Hashimoto Speaker](/img/speakers/thashim.jpg){:width="150px"}
> <b>Title:</b> Understanding generalization for instruction following and black-box language models
> 
> <b>Abstract:</b> Instruction following language models have shown a remarkable ability to perform a wide range of tasks with little to no additional training data. Do these abilities come from a revolution in pre-training and instruction-following, or are there other more mundane explanations for how these models work? In this talk, I will discuss our efforts to answer these questions by replicating instruction-following models that generalize across tasks, studying the consistency of these models across different task formats, and building tests for benchmark contamination in pretraining.

### <span style="color:grey">14:45-15:30 PM —</span> Oral presentations

- <b><span style="color:grey">14:45-15:00 PM — </span> Evaluating Neural Language Models as Cognitive Models of Language Acquisition</b><br>
Hector Javier Vazquez Martinez, Annika Lea Heuser, Charles Yang, Jordan Kodner

- <b><span style="color:grey">15:00-15:15 PM — </span> Understanding Code Semantics: An Evaluation of Transformer Models in Summarization</b><br>
Debanjan Mondal, Abhilasha Lodha, Ankita Sahoo, Beena Kumari

- <b><span style="color:grey">15:00-15:15 PM — </span> Cross-Lingual Data Augmentation For Thai Question-Answering</b><br>
Parinthapat Pengpun, Can Udomcharoenchaikit, Weerayut Buaphet, Peerat Limkonchotiwat


### <span style="color:grey">15:30-16:00 PM —</span> Coffee break
### <span style="color:grey">16:00-17:00 PM —</span> Poster session 2 (hybrid)
<!---
<details>
<summary>Click to toggle an overview of the posters that will be presented in this session.</summary>
<ul>
  <li>This is a test. The titles and authors will be inserted when the selection is complete.</li>
</ul>
</details>
--->

### <span style="color:grey">17:00-17:30PM —</span> Pannel
### <span style="color:grey">17:30-17:45PM —</span> Closing remarks and best paper award

