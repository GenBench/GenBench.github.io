---
permalink: /workshop_programme/
title: "Workshop programme"
toc: false
author_profile: false
layout: single_wide
toc_sticky: true
excerpt: "The programme of the second workshop on generalisation (benchmarking) in NLP"
header:
  overlay_color: "#268"
---

# Programme

Note that all time slots listed below are in Eastern Standard Time (UTC-5) and that all sessions take place in the Brickell room. The programme is tentative at the moment!

## Morning programme

### <span style="color:grey">09:00-09:15 AM —</span> Opening remarks
### <span style="color:grey">09:15-10:00 AM —</span> Keynote 1, by Najoung Kim

![Najoung Kim Speaker](/img/speakers/najoung.png){:width="200px"}

<b>Title:</b> Semantic generalizations in humans and machines <br />

<b>Abstract:</b> Do machines "understand"? Empirically addressing this question requires an operationalization of what it means to understand. In this talk, I will discuss three tests for machines grounded in formal semantic theories that characterize various aspects of human linguistic understanding, examining the capacities to assign adequate meaning representations to linguistic expressions, to track entities and their states in discourse, and to draw adequate inferences from complex expressions. Critically, these capacities must _generalize_ to unseen expressions. I will discuss the findings from these studies contextualized with respect to human capacities.

<b>Bio:</b> Najoung Kim is an Assistant Professor at the Department of Linguistics and an affiliate faculty in the Department of Computer Science at Boston University. She is also currently a visiting faculty researcher at Google DeepMind. Before joining BU, she was a Faculty Fellow at the Center for Data Science at New York University and received her PhD in Cognitive Science at Johns Hopkins University. She is interested in studying meaning in both human and machine learners, especially ways in which they generalize to novel inputs and ways in which they treat implicit meaning. Her research has been supported by NSF and Google, and has received awards at venues such as ACL and *SEM.

### <span style="color:grey">10:00-10:30 AM —</span> Oral presentations

- <b><span style="color:grey">10:00-10:15 PM — </span> [Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don’t mimic the full human distribution](https://aclanthology.org/2024.genbench-1.9.pdf) </b><br>
Hayley Ross, Kathryn Davidson, Najoung Kim

- <b><span style="color:grey">10:15-10:30 PM — </span> [Investigating the Generalizability of Pretrained Language Models across Multiple Dimensions: A Case Study of NLI and MRC](https://aclanthology.org/2024.genbench-1.11.pdf)</b><br>
Ritam Dutt, Sagnik Ray Choudhury, Varun Venkat Rao, Carolyn Rose, V.G. Vinod Vydiswaran

### <span style="color:grey">10:30-11:00 AM —</span> Coffee break

### <span style="color:grey">11:00-11:45 AM —</span> Keynote 2, by Kyle Lo

![Kyle Lo Speaker](/img/speakers/kyle.jpg){:width="200px"}

<b>Bio</b>: Kyle Lo is a research scientist at the Allen Institute for AI in Seattle, co-leading the pretraining data team for OLMo. His research focuses on open language models, domain adaptation and specialization, evaluation methods, and human-AI interaction. His award-winning work has appeared in major conferences like ACL, EMNLP and CHI, and been featured articles in Nature, Science, TechCrunch and others. In 2020, he co-led a White House OSTP initiative to publicly release the largest collection of COVID-19 research for computing use. Kyle holds a Statistics degree from the University of Washington and enjoys board games, boba tea, D&D, and his cat Belphegor.

### <span style="color:grey">11:45-12:30 AM —</span> Spotlight presentations

- <b>[MLissard: Multilingual Long and Simple Sequential Reasoning Benchmarks](https://aclanthology.org/2024.genbench-1.6.pdf) </b><br>
Mirelle Candida Bueno (presenter), Roberto Lotufo, Rodrigo Frassetto Nogueira

- <b>[OmniDialog: A Multimodal Benchmark for Generalization Across Text, Visual, and Audio Modalities](https://aclanthology.org/2024.genbench-1.12.pdf)</b><br>
Anton Razzhigaev, Maxim Kurkin (presenter), Elizaveta Goncharova, Irina Abdullaeva, Anastasia Lysenko, Alexander Panchenko, Andrey Kuznetsov, Denis Dimitrov

- <b>[MultiPragEval: Multilingual Pragmatic Evaluation of Large Language Models](https://aclanthology.org/2024.genbench-1.7.pdf)</b><br>
Dojun Park, Jiwoo Lee (presenter), Seohyun Park, Hyeyun Jeong, Youngeun Koo, Soonha Hwang, Seonwoo Park, Sungeun Lee

- <b>[The SlayQA benchmark of social reasoning: testing gender-inclusive generalization with neopronouns](https://aclanthology.org/2024.genbench-1.3.pdf)</b><br>
Bastian Bunzeck (presenter), Sina Zarrieß

- <b>[MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models](https://aclanthology.org/2024.genbench-1.5.pdf)</b><br>
Presenter: Hengyi Wang, Authors: Wentian Wang, Sarthak Jain, Paul Kantor, Jacob Feldman, Lazaros Gallos, Hao Wang

## <span style="color:grey"> 12:30-1:45 PM —</span> Lunch break


## Afternoon programme

### <span style="color:grey">1:45-3:00 PM —</span> Poster session

<ul>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <b><a href="https://aclanthology.org/2024.genbench-1.6.pdf">MLissard: Multilingual Long and Simple Sequential Reasoning Benchmarks</a></b> <br>
      Mirelle Candida Bueno, Roberto Lotufo, Rodrigo Frassetto Nogueira
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.12.pdf"><b>OmniDialog: A Multimodal Benchmark for Generalization Across Text, Visual, and Audio Modalities</b></a> <br>
      Anton Razzhigaev, Maxim Kurkin, Elizaveta Goncharova, Irina Abdullaeva, Anastasia Lysenko, Alexander Panchenko, Andrey Kuznetsov, Denis Dimitrov
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.7.pdf"><b>MultiPragEval: Multilingual Pragmatic Evaluation of Large Language Models</b></a> <br>
      Dojun Park, Jiwoo Lee, Seohyun Park, Hyeyun Jeong, Youngeun Koo, Soonha Hwang, Seonwoo Park, Sungeun Lee
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.2.pdf"><b>From Language to Pixels: Task Recognition and Task Learning in LLMs</b></a><br>
      Janek Falkenstein, Carolin M. Schuster, Alexander H Berger, Georg Groh
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.4.pdf"><b>Automated test generation to evaluate tool-augmented LLMs as conversational AI agents</b></a> <br>
      Samuel Arcadinho, David Oliveira Aparicio, Mariana S. C. Almeida
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.8.pdf"><b>Beyond the Numbers: Transparency in Relation Extraction Benchmark Creation and Leaderboards</b></a><br>
      Varvara Arzt, Allan Hanbury
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.10.pdf"><b>CHIE: Generative MRC Evaluation for in-context QA with Correctness, Helpfulness, Irrelevancy, and Extraneousness Aspects</b></a> <br>
      Wannaphong Phatthiyaphaibun, Surapon Nonesung, Peerat Limkonchotiwat, Can Udomcharoenchaikit, Jitkapat Sawatphol, Ekapol Chuangsuwanich, Sarana Nutanong
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.1.pdf"><b>Evaluating the fairness of task-adaptive pretraining on unlabeled test data before few-shot text classification</b></a> <br>
      Kush Dubey
  </li>
  <li>
      <span style="color:#ffffff; background-color: #ab438a; border-radius:4px; padding:3px">GenBench</span> <a href="https://aclanthology.org/2024.genbench-1.13.pdf"><b>Towards a new Benchmark for Emotion Detection in NLP: A Unifying Framework of Recent Corpora</b></a> <br>
      Anna Koufakou, Elijah Nieves, John Peller
  </li>  
  <li>
      <span style="color:#ffffff; background-color: #74849c; border-radius:4px; padding:3px">GenBench CBT</span> <a href="https://aclanthology.org/2024.genbench-1.3.pdf"><b>The SlayQA benchmark of social reasoning: testing gender-inclusive generalization with neopronouns</b></a> <br>
      Bastian Bunzeck, Sina Zarrieß
  </li>
  <li>
      <span style="color:#ffffff; background-color: #74849c; border-radius:4px; padding:3px">GenBench CBT</span> <a href="https://aclanthology.org/2024.genbench-1.5.pdf"><b>MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large Language Models</b></a> <br>
      Presenter: Hengyi Wang, Authors: Wentian Wang, Sarthak Jain, Paul Kantor, Jacob Feldman, Lazaros Gallos, Hao Wang
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/18_A_Peek_into_Token_Bias_Larg.pdf"><b>A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners</b></a> <br>
      Bowen Jiang, Yangxinyu Xie, Zhuoqun Hao, Xiaomeng Wang, Tanwi Mallick, Weijie J Su, Camillo Jose Taylor, Dan Roth
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/24_Cross_Domain_Question_Gener.pdf"><b>Cross-Domain Question Generation: A Comparative Study</b> </a> <br>
      Niloufar Beyranvand, Aijun An, Heidar Davoudi
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/19_The_Relationship_Between_Co.pdf"><b>The Relationship Between Compositional Generalization and Misinformation in Emergent Communication</b></a> <br>
      Heeyoung Lee
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <b>NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization</b> <br>
      Danial Kamali, Elham Barezi, Parisa Kordjamshidi
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/14_Benchmarking_Foundation_Mod.pdf"><b>Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation</b></a> <br>
      Suho Kang, Jungyang Park, Joonseo Ha, SoMin Kim, JinHyeong Kim, Subeen Park, Kyungwoo Song
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/31_LUCY_Linking_Uncertainty_an.pdf"><b>LUCY: Linking Uncertainty and ConsistencY of Large Language Models for Question Answering</b></a> <br>
      Urja Khurana, Lea Krause
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/15_Can_General_Purpose_Large_L.pdf"><b>Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation?</b></a> <br> 
      Jirat Chiaranaipanich, Naiyarat Hanmatheekuna, Jitkapat Sawatphol, Krittamate Tiankanon, Jiramet Kinchagawat, Amrest Chinkamol, Parinthapat Pengpun, Piyalitt Ittichaiwong, Peerat Limkonchotiwat
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/30_Towards_Dynamic_and_Realist.pdf"><b>Towards Dynamic and Realistic Evaluation of Multi-modal Large Language Model</b></a> <br>
      Huiqi Zou, Yijiang Li, Ziang Xiao
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0ccfbb; border-radius:4px; padding:3px">GenBench Non-archival</span> <a href="/assets/extended_abstracts_2023/34_Leveraging_Isomorphisms_to_.pdf"><b>Leveraging Isomorphisms to facilitate Zero-Shot KBQA Generalization</b></a> <br>
      Ritam Dutt, Dongfang Ling, Yu Gu, Carolyn Rose
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0b7ef6; border-radius:4px; padding:3px">Findings</span> <a href="https://arxiv.org/abs/2306.00168"><b>Measuring the Robustness of NLP Models to Domain Shifts</b></a> <br>
      Nitay Calderon, Naveh Porat, Eyal Ben-David, Alexander Chapanin, Zorik Gekhman, Nadav Oved, Vitaly Shalumov, Roi Reichart
  </li>
  <li>
      <span style="color:#ffffff; background-color: #0b7ef6; border-radius:4px; padding:3px">Findings</span> <a href="https://arxiv.org/abs/2402.04957v3"><b>Reconfidencing LLM Uncertainty from the Grouping Loss Perspective</b></a> <br>
      Lihu Chen, Alexandre Perez-Lebel, Fabian M. Suchanek, Gaël Varoquaux
  </li>
</ul>

### <span style="color:grey">3:00-3:45 PM —</span> Keynote 3, by Sameer Singh

![Sameer Singh Speaker](/img/speakers/sameer.png){:width="200px"}

<b>Bio:</b>Dr. Sameer Singh is a Professor of Computer Science at the University of California, Irvine (UCI) and a Cofounder/CTO of Spiffy AI. He is working primarily on the evaluation, robustness, and interpretability of machine learning algorithms and large models that reason with text and structure for natural language processing. He has been named the Kavli Fellow by the National Academy of Sciences, received the NSF CAREER award, UCI Distinguished Early Career Faculty award, the Hellman Faculty Fellowship, and was selected as a DARPA Riser. His group has received funding from Allen Institute for AI, Amazon, NSF, DARPA, Adobe Research, Hasso Plattner Institute, NEC, Base 11, and FICO. Sameer has published extensively at machine learning and natural language processing venues and received numerous paper awards, including at KDD 2016, ACL 2018, EMNLP 2019, AKBC 2020, ACL 2020, and NAACL 2022.

### <span style="color:grey">3:45-4:00 PM —</span> Coffee break
### <span style="color:grey">4:00-4:30 PM —</span> Panel
### <span style="color:grey">4:30-4:45 PM —</span> Closing remarks and best paper award
